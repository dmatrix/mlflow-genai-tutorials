{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1.4: Manual Tracing and Advanced Observability\n",
    "\n",
    "![](images/5_Advanced-Observability-with-Manual-Tracing.png)\n",
    "## Custom Instrumentation for Complex Workflows\n",
    "\n",
    "Welcome to advanced tracing! While autologging is powerful, real-world applications often need custom instrumentation. You'll learn how to trace your own functions and build hierarchical observability into complex GenAI workflows.\n",
    "\n",
    "### What You'll Learn\n",
    "- When to use manual tracing vs. autologging\n",
    "- The `@mlflow.trace` decorator\n",
    "- Creating custom spans with proper types\n",
    "- Adding custom attributes to spans\n",
    "- Building hierarchical traces (parent-child relationships)\n",
    "- Tracing RAG pipelines end-to-end\n",
    "- Tracing agentic workflows with tool usage\n",
    "- Advanced debugging techniques\n",
    "- Using Claude Code Assistant for inspecting and debugging\n",
    "\n",
    "### Prerequisites\n",
    "- Completed Notebook 1.3 (Introduction to Tracing)\n",
    "- Understanding of autologging\n",
    "- MLflow UI running\n",
    "\n",
    "### Estimated Time: 30-35 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: When to Use Manual Tracing\n",
    "\n",
    "### Autologging is Great For:\n",
    "- ‚úÖ LLM API calls (OpenAI, Anthropic, Gemmini, etc.)\n",
    "- ‚úÖ Integrated Framework chains (LangChain, LlamaIndex, Vercel)\n",
    "- ‚úÖ Quick prototyping\n",
    "- ‚úÖ Standard workflows\n",
    "\n",
    "### Manual Tracing is Needed For:\n",
    "- ‚úÖ **Custom functions** in your pipeline\n",
    "- ‚úÖ **Domain-specific operations** (parsing, validation, business logic)\n",
    "- ‚úÖ **Custom retrievers** or data sources\n",
    "- ‚úÖ **External API calls** not auto-instrumented\n",
    "- ‚úÖ **Adding context** not captured automatically\n",
    "- ‚úÖ **Organizing operations** into logical groups\n",
    "\n",
    "### Best Practice: Combine Both!\n",
    "```python\n",
    "# Use autologging for LLM calls\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "# Add manual tracing for custom logic\n",
    "@mlflow.trace\n",
    "def my_custom_function(query):\n",
    "    # Your custom code\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/27 11:43:00 INFO mlflow.tracking.fluent: Experiment with name '07-manual-tracing' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment configured: using OpenAI client\n",
      "   MLflow version: 3.10.0\n",
      "   Tracking URI: http://localhost:5000\n",
      "‚úÖ Environment configured\n",
      "   Ready for manual tracing!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import mlflow\n",
    "from dotenv import load_dotenv\n",
    "from utils.clnt_utils import is_databricks_ai_gateway_client, get_databricks_ai_gateway_client, get_openai_client, get_ai_gateway_model_names\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "\n",
    "# Configure MLflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "use_databricks_provider = is_databricks_ai_gateway_client()\n",
    "if use_databricks_provider:\n",
    "    client = get_databricks_ai_gateway_client()\n",
    "    model_name = get_ai_gateway_model_names()[0]\n",
    "else:\n",
    "    # Initialize OpenAI\n",
    "    client = get_openai_client()\n",
    "    model_name = \"gpt-5-mini\"\n",
    "print(\"‚úÖ Environment configured: using\", \"Databricks\" if use_databricks_provider else \"OpenAI\", \"client\")\n",
    "print(f\"   MLflow version: {mlflow.__version__}\")\n",
    "print(f\"   Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "\n",
    "# Create experiment\n",
    "mlflow.set_experiment(\"07-manual-tracing\")\n",
    "\n",
    "print(\"‚úÖ Environment configured\")\n",
    "print(\"   Ready for manual tracing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Your First Manual Trace\n",
    "\n",
    "Let's trace a custom function using the `@mlflow.trace` decorator, giving us the control what specific calls to trace as we might\n",
    "have custom logic that we want trace and debug in case of issues. MLflow privdes a decorator `@mlflow.trace`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Testing manual tracing...\n",
      "\n",
      "Input: '  What is MLflow?  '\n",
      "Output: what is mlflow?\n",
      "\n",
      "‚úÖ Function traced!\n",
      "\n",
      "üìä In MLflow UI, you'll see:\n",
      "   - Span name: preprocess_query\n",
      "   - Input: original query\n",
      "   - Output: processed query\n",
      "   - Duration: ~100ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-3b0fcd105c6b6277e144bcf9bc5b9d6d&amp;experiment_id=1&amp;version=3.10.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=tr-3b0fcd105c6b6277e144bcf9bc5b9d6d)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Decorate the function with the @mlflow.trace decorator\n",
    "# This will trace the function and log it to MLflow\n",
    "@mlflow.trace\n",
    "def simulate_custom_query_processing(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Simulate custom query processing logic.\n",
    "    \"\"\"\n",
    "    # Simulate work\n",
    "    time.sleep(0.1)\n",
    "    return query.strip().lower()\n",
    "\n",
    "\n",
    "# Simple example: Trace a custom function\n",
    "@mlflow.trace \n",
    "def preprocess_query(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Preprocess user query before sending to LLM.\n",
    "    This is a custom function that MLflow doesn't auto-trace.\n",
    "    \"\"\"\n",
    "    # Simulate preprocessing\n",
    "    processed = simulate_custom_query_processing(user_query)\n",
    "    \n",
    "    # This function is now fully traced,along with the custom function simulate_custom_query_processing!\n",
    "    return processed\n",
    "\n",
    "# Test it\n",
    "print(\"\\nüîç Testing manual tracing...\\n\")\n",
    "\n",
    "result = preprocess_query(\"  What is MLflow?  \")\n",
    "\n",
    "print(\"Input: '  What is MLflow?  '\")\n",
    "print(f\"Output: {result}\")\n",
    "print(\"\\n‚úÖ Function traced!\")\n",
    "print(\"\\nüìä In MLflow UI, you'll see:\")\n",
    "print(\"   - Span name: preprocess_query\")\n",
    "print(\"   - Input: original query\")\n",
    "print(\"   - Output: processed query\")\n",
    "print(\"   - Duration: ~100ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ What Just Happened?\n",
    "\n",
    "The `@mlflow.trace` decorator:\n",
    "1. **Captured** function inputs and outputs\n",
    "2. **Measured** execution time\n",
    "3. **Created** spans of all function invoked in the trace\n",
    "4. **Logged** everything to MLflow\n",
    "\n",
    "**No manual logging code needed!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Span Types and Names\n",
    "\n",
    "MLflow defines üìã Standard Span Types:\n",
    "\n",
    "- `CHAIN`: A sequence of operations\n",
    "- `LLM`: Language model call\n",
    "- `RETRIEVER`: Document retrieval\n",
    "- `EMBEDDING`: Text embedding\n",
    "- `TOOL`: Tool/function execution\n",
    "- `AGENT`: Agent reasoning\n",
    "- `PARSER`: Output parsing or generic intermediate parsing of an outcome \n",
    "\n",
    "\n",
    "You can specify span types to categorize operations, and attach names to it by providing arguments to the decorator.\n",
    "\n",
    "Let's look at some examples where we use these types to get a feel for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define our functions with appropriate SPAN types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "# Specify span type and custom name\n",
    "@mlflow.trace(name=\"document_retriever\", span_type=\"RETRIEVER\")\n",
    "def retrieve_documents(query: str, top_k: int = 3) -> List[str]:\n",
    "    \"\"\"\n",
    "    Simulate document retrieval from a vector database.\n",
    "    Subsitute this with a real vector database call.\n",
    "    \"\"\"\n",
    "    time.sleep(0.4)  # Simulate vector search\n",
    "    \n",
    "    # Simulated documents\n",
    "    docs = [\n",
    "        \"MLflow is an open source platform for the ML and GenAI Applications and AI Observability.\",\n",
    "        \"MLflow Tracing provides end-to-end observability for GenAI applications.\",\n",
    "        \"MLflow supports experiment tracking and LLM tracing, model registry, prompt management and optimization, and AI Gateway.\"\n",
    "    ]\n",
    "    \n",
    "    return docs[:top_k]\n",
    "\n",
    "@mlflow.trace(name=\"get_embedding\", span_type=\"LLM\")\n",
    "def get_embedding(query: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Generate embedding for query. \n",
    "    Use OpenAI's embedding API to create an embedding for the query.\n",
    "    \"\"\"\n",
    "    query = query.replace(\"\\n\", \" \")\n",
    "\n",
    "    # Call openai to create an embedding\n",
    "    response = client.embeddings.create(input=query, model=\"text-embedding-3-small\")\n",
    "\n",
    "    # Get the embedding from the response\n",
    "    embedding = response.data[0].embedding\n",
    "\n",
    "    return embedding\n",
    "\n",
    "@mlflow.trace(name=\"query_embedder\", span_type=\"EMBEDDING\")\n",
    "def embed_query(query: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Embed query using OpenAI's embedding API.\n",
    "    \"\"\"\n",
    "    return get_embedding(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run our functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìö Testing typed spans...\n",
      "\n",
      "Embedding: [0.00023487683210987598, -0.008157051168382168, -0.0052101886831223965]...\n",
      "\n",
      "Retrieved 2 documents\n",
      "  Doc 1: MLflow is an open source platform for the ML and GenAI Applications and AI Observability....\n",
      "  Doc 2: MLflow Tracing provides end-to-end observability for GenAI applications....\n",
      "\n",
      "‚úÖ Typed spans created!\n",
      "\n",
      "üîç In MLflow UI:\n",
      "   - get_embedding: Type = LLM\n",
      "   - embed_query: Type = EMBEDDING\n",
      "   - retrieve_documents: Type = RETRIEVER\n",
      "   - Easy to filter by operation type!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-69388e185f4b97ce3057776f592e4a80&amp;experiment_id=1&amp;trace_id=tr-d33a6e6e68c1be1064a114db94aaf340&amp;experiment_id=1&amp;version=3.10.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(trace_id=tr-69388e185f4b97ce3057776f592e4a80), Trace(trace_id=tr-d33a6e6e68c1be1064a114db94aaf340)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test our  functions\n",
    "print(\"\\nüìö Testing typed spans...\\n\")\n",
    "\n",
    "query = \"What is MLflow for AI Platform or AI Observability?\"\n",
    "\n",
    "# These will create different span types\n",
    "embedding = embed_query(query)\n",
    "print(f\"Embedding: {embedding[:3]}...\")\n",
    "\n",
    "documents = retrieve_documents(query, top_k=2)\n",
    "print(f\"\\nRetrieved {len(documents)} documents\")\n",
    "for i, doc in enumerate(documents, 1):\n",
    "    print(f\"  Doc {i}: {doc[:100]}...\")\n",
    "\n",
    "print(\"\\n‚úÖ Typed spans created!\")\n",
    "print(\"\\nüîç In MLflow UI:\")\n",
    "print(\"   - get_embedding: Type = LLM\")\n",
    "print(\"   - embed_query: Type = EMBEDDING\")\n",
    "print(\"   - retrieve_documents: Type = RETRIEVER\")\n",
    "print(\"   - Easy to filter by operation type!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Adding Custom Attributes\n",
    "\n",
    "For additional entities, you can enrich spans with additional metadata as attributes.\n",
    "These will be captured in the span and displayed in the MLflow UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Testing custom attributes...\n",
      "\n",
      "\n",
      "‚úÖ Span created with custom attributes!\n",
      "\n",
      "üîç Custom attributes visible in UI:\n",
      "   - top_k: 2\n",
      "   - query_length: 23\n",
      "   - search_method: vector_similarity\n",
      "   - num_results: 2\n",
      "   - total_docs_in_db: 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-25c47630fa8b4c1a8f8aa658f563547d&amp;experiment_id=1&amp;version=3.10.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=tr-25c47630fa8b4c1a8f8aa658f563547d)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add custom attributes to spans\n",
    "\n",
    "@mlflow.trace(name=\"enhanced_retriever\", span_type=\"RETRIEVER\")\n",
    "def enhanced_retriever(query: str, top_k: int = 3) -> List[str]:\n",
    "    \"\"\"\n",
    "    Retriever with rich metadata logging.\n",
    "    \"\"\"\n",
    "    span = mlflow.get_current_active_span()\n",
    "    # set attributes\n",
    "    span.set_attributes({\"top_k\":top_k,\n",
    "                        \"query_length\":len(query),\n",
    "                        \"search_method\":\"cosine_similarity\"})\n",
    "\n",
    "    # Simulate retrieval. Substitute this with a real vector database call.\n",
    "    time.sleep(0.4)\n",
    "    docs = [\n",
    "        \n",
    "        \"MLflow provides tracing capabilities for end-to-end Agentic workflows\"\n",
    "        \"MLflow logs all operations and events in a trace, providing a complete view of the workflow.\"\n",
    "        \"MLflow supports multiple agent frameworks like LangChain, LlamaIndex, and more for tracing\"\n",
    "    ]\n",
    "    \n",
    "    # set attributes\n",
    "    \n",
    "    span.set_attributes({\"num_results\": len(docs[:top_k]),\n",
    "                        \"total_docs_in_db\": 1000})  # Simulated\n",
    "    \n",
    "    return docs[:top_k]\n",
    "\n",
    "# Test it\n",
    "print(\"\\nüìä Testing custom attributes...\\n\")\n",
    "query = \"What is MLflow tracing?\"\n",
    "docs = enhanced_retriever(query, top_k=2)\n",
    "\n",
    "print(\"\\n‚úÖ Span created with custom attributes!\")\n",
    "print(\"\\nüîç Custom attributes visible in UI:\")\n",
    "print(\"   - top_k: 2\")\n",
    "print(f\"   - query_length: {len(query)}\")\n",
    "print(\"   - search_method: vector_similarity\")\n",
    "print(\"   - num_results: 2\")\n",
    "print(\"   - total_docs_in_db: 1000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Insight: When to Add Custom Attributes\n",
    "\n",
    "Add attributes for:\n",
    "- **Configuration** (top_k, model_name)\n",
    "- **Performance metrics** (num_results, cache_hit)\n",
    "- **Data characteristics** (query_length, doc_size)\n",
    "- **Business logic** (user_tier, feature_flags)\n",
    "- **Debugging info** (data_source, version)\n",
    "\n",
    "These make traces **searchable and analyzable**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Building Hierarchical Traces\n",
    "\n",
    "Let's try an example that is common in agentic workflows, hierarchy of steps.\n",
    "\n",
    "Create parent-child relationships between spans, using a CHAIN span type. This is typical of most GenAI or Agentic workflows where you'll have mult-step workflow with some hierarchy of operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define all the functions with relevant SPAN types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, List\n",
    "\n",
    "# Build a hierarchical trace\n",
    "@mlflow.trace(name=\"extract_intent_and_entities\", span_type=\"LLM\")\n",
    "def extract_intent_and_entities(query: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Call an LLM to extract intent and entities from the query.\n",
    "    Traced as an LLM span ‚Äî child of parse_query.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"You are a query parser. Given a user query, return a JSON object with:\\n\"\n",
    "        '- \"intent\": a single word describing the intent (e.g. \"question\", \"command\", \"request\")\\n'\n",
    "        '- \"entities\": a list of key nouns or topics mentioned in the query\\n\\n'\n",
    "        f'Query: \"{query}\"'\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        max_completion_tokens=1000\n",
    "    )\n",
    "    return json.loads(response.choices[0].message.content)\n",
    "\n",
    "@mlflow.trace(name=\"parse_query\", span_type=\"PARSER\")\n",
    "def parse_query(query: str) -> Dict:\n",
    "    \"\"\"Extract intent and entities from query.\n",
    "    This is a child span of the parent span rag_retrieval_pipeline.\n",
    "    \"\"\"\n",
    "\n",
    "    # Call LLM to extract intent and entities (child LLM span)\n",
    "    llm_result = extract_intent_and_entities(query)\n",
    "    return {\n",
    "        \"intent\": llm_result.get(\"intent\", \"question\"),\n",
    "        \"entities\": llm_result.get(\"entities\", []),\n",
    "        \"cleaned_query\": query.strip()\n",
    "    }\n",
    "\n",
    "@mlflow.trace(name=\"embed_text\", span_type=\"EMBEDDING\")\n",
    "def embed_text(text: str) -> List[float]:\n",
    "    \"\"\"Generate embedding.\"\"\"\n",
    "\n",
    "    # Call the embedding function which will be traced as an LLM span\n",
    "    embedding = get_embedding(text)\n",
    "    return embedding\n",
    "\n",
    "@mlflow.trace(name=\"vector_search\", span_type=\"RETRIEVER\")\n",
    "def vector_search(embedding: List[float], top_k: int = 3) -> List[Dict]:\n",
    "    \"\"\"Search vector database.\"\"\"\n",
    "    span = mlflow.get_current_active_span()\n",
    "    span.set_attributes({\"embedding_dim\": len(embedding),\n",
    "                         \"top_k\":top_k})\n",
    "\n",
    "    # Simulate vector search. Replace with actual vector search.\n",
    "    time.sleep(0.15)\n",
    "\n",
    "    return [\n",
    "        {\"text\": \"MLflow is an open source platform.\", \"score\": 0.95},\n",
    "        {\"text\": \"MLflow provides tracing.\", \"score\": 0.89},\n",
    "        {\"text\": \"MLflow supports deployments.\", \"score\": 0.82}\n",
    "    ][:top_k]\n",
    "\n",
    "# Test the hierarchical pipeline with a CHAIN span type\n",
    "@mlflow.trace(name=\"rag_retrieval_pipeline\", span_type=\"CHAIN\")\n",
    "def rag_retrieval_pipeline(user_query: str, top_k: int = 3) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Complete retrieval pipeline with multiple steps.\n",
    "    This parent span will contain all child spans!\n",
    "    \"\"\"\n",
    "    span = mlflow.get_current_active_span()\n",
    "    span.set_attributes({\"pipeline_version\":\"v1.0\",\n",
    "                         \"top_k\":top_k})\n",
    "    \n",
    "    # Step 1: Parse query (child span)\n",
    "    parsed = parse_query(user_query)\n",
    "    \n",
    "    # Step 2: Embed query (child span)\n",
    "    embedding = embed_text(parsed[\"cleaned_query\"])\n",
    "    \n",
    "    # Step 3: Vector search (child span)\n",
    "    results = vector_search(embedding, top_k=top_k)\n",
    "    span.set_attributes({\"num_results\": len(results)})\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üå≥ Testing hierarchical tracing...\n",
      "\n",
      "Retrieved 2 documents:\n",
      "  1. MLflow is an open source platform.... (score: 0.95)\n",
      "  2. MLflow provides tracing.... (score: 0.89)\n",
      "\n",
      "‚úÖ Hierarchical trace created!\n",
      "\n",
      "üå≥ Trace hierarchy:\n",
      "\n",
      "   rag_retrieval_pipeline (CHAIN)\n",
      "   ‚îú‚îÄ‚îÄ parse_query (PARSER)\n",
      "   ‚îÇ   ‚îî‚îÄ‚îÄ extract_intent_and_entities (LLM)\n",
      "   ‚îú‚îÄ‚îÄ embed_text (EMBEDDING)\n",
      "   ‚îÇ   ‚îî‚îÄ‚îÄ get_embedding (LLM)\n",
      "   ‚îî‚îÄ‚îÄ vector_search (RETRIEVER)\n",
      "\n",
      "View the timeline in MLflow UI to see the hierarchy!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-0e82b1628f49c9b07593241995310255&amp;experiment_id=1&amp;version=3.10.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=tr-0e82b1628f49c9b07593241995310255)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the hierarchical pipeline\n",
    "print(\"\\nüå≥ Testing hierarchical tracing...\\n\")\n",
    "\n",
    "results = rag_retrieval_pipeline(\"What is MLflow?\", top_k=2)\n",
    "\n",
    "print(f\"Retrieved {len(results)} documents:\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"  {i}. {result['text'][:40]}... (score: {result['score']})\")\n",
    "\n",
    "print(\"\\n‚úÖ Hierarchical trace created!\")\n",
    "print(\"\\nüå≥ Trace hierarchy:\")\n",
    "print(\"\"\"\n",
    "   rag_retrieval_pipeline (CHAIN)\n",
    "   ‚îú‚îÄ‚îÄ parse_query (PARSER)\n",
    "   ‚îÇ   ‚îî‚îÄ‚îÄ extract_intent_and_entities (LLM)\n",
    "   ‚îú‚îÄ‚îÄ embed_text (EMBEDDING)\n",
    "   ‚îÇ   ‚îî‚îÄ‚îÄ get_embedding (LLM)\n",
    "   ‚îî‚îÄ‚îÄ vector_search (RETRIEVER)\n",
    "\"\"\")\n",
    "print(\"View the timeline in MLflow UI to see the hierarchy!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üå≥ Hierarchical Tracing Benefits\n",
    "\n",
    "**Advantages:**\n",
    "- **Logical organization** of complex workflows\n",
    "- **Performance analysis** per operation\n",
    "- **Easy debugging** - identify which step failed\n",
    "- **Clear dependencies** between operations\n",
    "- **Aggregate metrics** at parent level\n",
    "\n",
    "**The parent span automatically:**\n",
    "- Contains all child spans\n",
    "- Calculates total duration\n",
    "- Preserves execution order\n",
    "- Shows the call stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Complete RAG Pipeline with Tracing\n",
    "\n",
    "Let's build a full RAG pipeline combining manual tracing and autologging.\n",
    "\n",
    "So far we have been granularly using `mlflow.trace(...)` manually, but it's\n",
    "a common practice to use both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the RAG functions with relevant SPAN types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autologging for OpenAI so inner API calls are also traced as child spans\n",
    "mlflow.openai.autolog()\n",
    "\n",
    "# Complete RAG implementation with comprehensive tracing\n",
    "\n",
    "@mlflow.trace(name=\"context_retrieval\", span_type=\"RETRIEVER\")\n",
    "def retrieve_context(query: str, top_k: int = 3) -> List[str]:\n",
    "    \"\"\"\n",
    "    Retrieve relevant context documents.\n",
    "    \"\"\"\n",
    "    span = mlflow.get_current_active_span()\n",
    "    span.set_attributes({\"retrieval_method\":\"semantic_search\",\n",
    "                         \"top_k\":top_k})\n",
    "\n",
    "    \n",
    "    # Simulate retrieval\n",
    "    # Replave this with actual vector store search.\n",
    "    # 1. embed the query\n",
    "    # 2. search the vector store\n",
    "    # 3. retrieve the top_k documents\n",
    "    time.sleep(0.10)\n",
    "    \n",
    "    # fake docs retrieved\n",
    "    docs = [\n",
    "        \"MLflow is an open source platform for managing ML and GenAI lifecycle.\",\n",
    "        \"MLflow Tracing captures LLM execution with detailed spans.\",\n",
    "        \"MLflow integrates with OpenAI, LangChain, and 30+ frameworks.\",\n",
    "        \"MLflow provides experiment tracking and model registry.\",\n",
    "        \"MLflow supports deployment to various serving platforms.\"\n",
    "    ]\n",
    "    \n",
    "    retrieved = docs[:top_k]\n",
    "    span.set_attributes({\"num_docs_retrieved\": len(retrieved)})\n",
    "    \n",
    "    return retrieved\n",
    "\n",
    "@mlflow.trace(name=\"format_prompt\", span_type=\"PARSER\")\n",
    "def format_rag_prompt(query: str, context_docs: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Format RAG prompt with context and query.\n",
    "    \"\"\"\n",
    "    span = mlflow.get_current_active_span()\n",
    "    span.set_attributes({\"num_context_docs\": len(context_docs)})\n",
    "    \n",
    "    context = \"\\n\".join([f\"- {doc}\" for doc in context_docs])\n",
    "    \n",
    "    prompt = f\"\"\"Use the following context to answer the question:\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer concisely based on the context above:\"\"\"\n",
    "    span.set_attributes({\"prompt_length\": len(prompt)})\n",
    "    span.set_attributes({\"prompt\": prompt})\n",
    "    span.set_attributes({\"query\": query})\n",
    "    span.set_attributes({\"context\": context})\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "@mlflow.trace(name=\"generate_answer\", span_type=\"LLM\")\n",
    "def generate_answer(prompt: str, model: str = \"gpt-5-mini\") -> str:\n",
    "    \"\"\"\n",
    "    Generate answer using LLM.\n",
    "    The OpenAI call will appear as a child span via autologging.\n",
    "    \"\"\"\n",
    "    span = mlflow.get_current_active_span()\n",
    "    span.set_attributes({\"model\": model})\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_completion_tokens=2000\n",
    "    )\n",
    "    \n",
    "    answer = response.choices[0].message.content\n",
    "    \n",
    "    span.set_attributes({\"answer_length\": len(answer),\n",
    "                         \"tokens_used\": response.usage.total_tokens})\n",
    "    \n",
    "    return answer\n",
    "\n",
    "# Complete RAG implementation with comprehensive tracing\n",
    "# The entire pipeline is traced manually\n",
    "@mlflow.trace(name=\"rag_qa_system\", span_type=\"CHAIN\")\n",
    "def rag_qa_system(user_query: str, top_k: int = 3) -> Dict:\n",
    "    \"\"\"\n",
    "    Complete RAG question-answering system.\n",
    "    \n",
    "    Returns:\n",
    "        Dict with answer, context, and metadata\n",
    "    \"\"\"\n",
    "    span = mlflow.get_current_active_span()\n",
    "    span.set_attributes({\"system_version\": \"v1.0\",\n",
    "                         \"user_query\": user_query})\n",
    "    \n",
    "    # Step 1: Retrieve context (manually traced)\n",
    "    context_docs = retrieve_context(user_query, top_k=top_k)\n",
    "    \n",
    "    # Step 2: Format prompt (manually traced)\n",
    "    prompt = format_rag_prompt(user_query, context_docs)\n",
    "    \n",
    "    # Step 3: Generate answer (manually traced + OpenAI call auto-traced)\n",
    "    answer = generate_answer(prompt, model_name)\n",
    "    \n",
    "    result = {\n",
    "        \"query\": user_query,\n",
    "        \"answer\": answer,\n",
    "        \"context_docs\": context_docs,\n",
    "        \"num_docs_used\": len(context_docs)\n",
    "    }\n",
    "    span.set_attributes({\"answer_generated\": True})\n",
    "    \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Testing complete RAG system with full tracing...\n",
      "\n",
      "Query: What tracing capabilities does MLflow provide?\n",
      "\n",
      "Context docs used: 3\n",
      "\n",
      "Answer:\n",
      "- Captures LLM execution as detailed traces/spans (MLflow Tracing).\n",
      "- Records fine-grained execution information (detailed spans) for debugging and auditing.\n",
      "- Works across integrations (OpenAI, LangChain and 30+ other frameworks) to provide end-to-end traceability of ML/GenAI workflows.\n",
      "\n",
      "============================================================\n",
      "‚úÖ RAG System Complete with Full Observability!\n",
      "============================================================\n",
      "\n",
      "\n",
      "üîç Trace Hierarchy in MLflow UI:\n",
      "\n",
      "rag_qa_system (CHAIN)\n",
      "‚îú‚îÄ‚îÄ context_retrieval (RETRIEVER)\n",
      "‚îú‚îÄ‚îÄ format_prompt (PARSER)\n",
      "‚îî‚îÄ‚îÄ generate_answer (LLM)\n",
      "    ‚îî‚îÄ‚îÄ OpenAI API call (auto-traced)\n",
      "\n",
      "Each span includes:\n",
      "‚úì Inputs and outputs\n",
      "‚úì Duration and timing\n",
      "‚úì Custom attributes\n",
      "‚úì Error information (if any)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-a9b582b1319413b5410ddc5bc8413a33&amp;experiment_id=1&amp;version=3.10.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(trace_id=tr-a9b582b1319413b5410ddc5bc8413a33)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the complete RAG system\n",
    "print(\"\\nü§ñ Testing complete RAG system with full tracing...\\n\")\n",
    "\n",
    "result = rag_qa_system(\"What tracing capabilities does MLflow provide?\", top_k=3)\n",
    "\n",
    "print(f\"Query: {result['query']}\")\n",
    "print(f\"\\nContext docs used: {result['num_docs_used']}\")\n",
    "print(f\"\\nAnswer:\\n{result['answer']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ RAG System Complete with Full Observability!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "\\nüîç Trace Hierarchy in MLflow UI:\n",
    "\n",
    "rag_qa_system (CHAIN)\n",
    "‚îú‚îÄ‚îÄ context_retrieval (RETRIEVER)\n",
    "‚îú‚îÄ‚îÄ format_prompt (PARSER)\n",
    "‚îî‚îÄ‚îÄ generate_answer (LLM)\n",
    "    ‚îî‚îÄ‚îÄ OpenAI API call (auto-traced)\n",
    "\n",
    "Each span includes:\n",
    "‚úì Inputs and outputs\n",
    "‚úì Duration and timing\n",
    "‚úì Custom attributes\n",
    "‚úì Error information (if any)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ RAG Pipeline Analysis\n",
    "\n",
    "With this tracing setup, you can:\n",
    "\n",
    "1. **Identify bottlenecks**: Which step takes longest?\n",
    "2. **Debug failures**: Which step failed and why?\n",
    "3. **Optimize retrieval**: Is top_k=3 optimal?\n",
    "4. **Track costs**: How many tokens per query?\n",
    "5. **Monitor quality**: Are retrieved docs relevant?\n",
    "\n",
    "**All visible in the MLflow UI timeline view!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8: Tracing Agentic Workflows with Tools Usage\n",
    "\n",
    "Tool usage is common in Agentic Worfkows. Tools could be user defined functions, which may use an external web service,\n",
    "or tools available via the MCP Server\n",
    "\n",
    "Let's trace an agent with tool usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agentic workflow with tool usage\n",
    "\n",
    "@mlflow.trace(name=\"weather_tool\", span_type=\"TOOL\")\n",
    "def get_weather(city: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Simulated weather tool.\n",
    "    \"\"\"\n",
    "    # get the current span associated with the trace\n",
    "    span = mlflow.get_current_active_span()\n",
    "    span.set_attributes({\n",
    "        \"tool_name\": \"weather_api\",\n",
    "        \"city\": city,\n",
    "        \"api_version\": \"v2.0\"\n",
    "    })\n",
    "    \n",
    "    # replace with actual API call to weather service\n",
    "    # you'll need to have an service account API key for this to work\n",
    "    # we are just simulating a slow API call here\n",
    "    time.sleep(0.2)  # Simulate API call\n",
    "    \n",
    "    # replace with actual API call to weather service\n",
    "    # results will be a JSON object\n",
    "    weather_data = {\n",
    "        \"city\": city,\n",
    "        \"temperature\": \"72¬∞F\",\n",
    "        \"condition\": \"Sunny\",\n",
    "        \"humidity\": \"45%\"\n",
    "    }\n",
    "    \n",
    "    span.set_attributes({   \n",
    "        \"data_retrieved\": True\n",
    "    })\n",
    "    \n",
    "    return weather_data\n",
    "\n",
    "# Another tool to use for the agent\n",
    "@mlflow.trace(name=\"calculator_tool\", span_type=\"TOOL\")\n",
    "def calculate(expression: str) -> float:\n",
    "    \"\"\"\n",
    "    Simulated calculator tool.\n",
    "    \"\"\"\n",
    "    span = mlflow.get_current_active_span()\n",
    "    span.set_attributes({\n",
    "        \"tool_name\": \"calculator\",\n",
    "        \"expression\": expression\n",
    "    })\n",
    "    \n",
    "    time.sleep(0.05)\n",
    "    \n",
    "    # UNSAFE: Don't use eval() in production!\n",
    "    # replace with actual calculator service\n",
    "    # eval() is used here for simplicitly\n",
    "    # but it can be injected with malicious code\n",
    "    result = eval(expression)\n",
    "    \n",
    "    span.set_attributes({\n",
    "        \"result\": result\n",
    "    })\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "@mlflow.trace(name=\"generate_random_password\", span_type=\"TOOL\")\n",
    "def generate_random_password(length: int) -> str:\n",
    "    \"\"\"\n",
    "    Generate a cryptographically strong random password.\n",
    "    Guarantees at least one uppercase, lowercase, digit, and special character.\n",
    "    \"\"\"\n",
    "    import secrets\n",
    "    import string\n",
    "\n",
    "    span = mlflow.get_current_active_span()\n",
    "    span.set_attributes({\n",
    "        \"tool_name\": \"generate_random_password\",\n",
    "        \"length\": length\n",
    "    })\n",
    "\n",
    "    if length < 8:\n",
    "        raise ValueError(\"Password length must be at least 8 characters\")\n",
    "\n",
    "    lowercase = string.ascii_lowercase\n",
    "    uppercase = string.ascii_uppercase\n",
    "    digits    = string.digits\n",
    "    special   = \"!@#$%^&*()_+-=[]{}|;:,.<>?\"\n",
    "\n",
    "    # Guarantee one character from each required set\n",
    "    password = [\n",
    "        secrets.choice(lowercase),\n",
    "        secrets.choice(uppercase),\n",
    "        secrets.choice(digits),\n",
    "        secrets.choice(special),\n",
    "    ]\n",
    "\n",
    "    # Fill the rest from the full combined pool\n",
    "    all_chars = lowercase + uppercase + digits + special\n",
    "    password += [secrets.choice(all_chars) for _ in range(length - 4)]\n",
    "\n",
    "    # Shuffle so the guaranteed characters aren't always at the front\n",
    "    secrets.SystemRandom().shuffle(password)\n",
    "\n",
    "    return \"\".join(password)\n",
    "\n",
    "\n",
    "# The agent planning step in deciding which tool to use\n",
    "# based on the user . It uses the LLM to plan.\n",
    "@mlflow.trace(name=\"agent_planning\", span_type=\"AGENT\")\n",
    "def agent_plan(user_query: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Agent decides which tool to use.\n",
    "    \"\"\"\n",
    "    span = mlflow.get_current_active_span()\n",
    "    span.set_attributes({\n",
    "        \"user_query\": user_query\n",
    "    })\n",
    "    \n",
    "    # Use LLM to plan (auto-traced)\n",
    "    system_prompt = \"\"\"You are an agent with access to:\n",
    "1. get_weather(city) - Get weather information\n",
    "2. calculate(expression) - Evaluate math expressions\n",
    "3. generate_random_password(length) - Generate a random password\n",
    "\n",
    "Decide which tool to use and extract parameters.\n",
    "Respond with JSON: {\"tool\": \"tool_name\", \"params\": {...}}\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_query}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    # Use the LLM's plan directly as a JSON object\n",
    "    plan = json.loads(response.choices[0].message.content)\n",
    "    span.set_attributes({\n",
    "        \"selected_tool\": plan[\"tool\"]\n",
    "    })\n",
    "    \n",
    "    return plan\n",
    "\n",
    "# run the agent in a chain\n",
    "@mlflow.trace(name=\"agent_execution\", span_type=\"CHAIN\")\n",
    "def run_agent(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Complete agent execution with planning and tool use.\n",
    "    \"\"\"\n",
    "    span = mlflow.get_current_active_span()\n",
    "    span.set_attributes({\n",
    "        \"agent_version\": \"v1.0\",\n",
    "        \"user_query\": user_query\n",
    "    })\n",
    "    \n",
    "    # Step 1: Plan (uses LLM)\n",
    "    plan = agent_plan(user_query)\n",
    "    \n",
    "    # Step 2: Execute the tool the LLM selected\n",
    "    if plan[\"tool\"] == \"get_weather\":\n",
    "        tool_result = get_weather(plan[\"params\"][\"city\"])\n",
    "    elif plan[\"tool\"] == \"calculate\":\n",
    "        tool_result = calculate(plan[\"params\"][\"expression\"])\n",
    "    elif plan[\"tool\"] == \"generate_random_password\":\n",
    "        tool_result = generate_random_password(plan[\"params\"][\"length\"])\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown tool: {plan['tool']}\")\n",
    "    \n",
    "    span.set_attributes({\n",
    "        \"tool_executed\": plan[\"tool\"]\n",
    "    })\n",
    "    \n",
    "    # Step 3: Generate final response (uses LLM)\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Tool result: {tool_result}. Answer: {user_query}\"\n",
    "        }],\n",
    "        max_completion_tokens=1000\n",
    "    )\n",
    "    \n",
    "    final_answer = response.choices[0].message.content\n",
    "    \n",
    "    span.set_attributes({\n",
    "        \"answer_generated\": True\n",
    "    })\n",
    "    \n",
    "    return final_answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the Agent tool usage workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Testing agentic workflow with tool tracing...\n",
      "\n",
      "Query: What's the weather in San Francisco?\n",
      "Answer: Currently in San Francisco it's 72¬∞F and sunny with 45% humidity. Want a forecast or hourly conditions?\n",
      "\n",
      "Query: Calculate 42 times 2 and divide by 2\n",
      "Answer: 42\n",
      "\n",
      "(42 √ó 2 = 84; 84 √∑ 2 = 42 ‚Äî multiplying and then dividing by the same nonzero number returns the original value.)\n",
      "Query: Generate a random password with 12 characters\n",
      "\n",
      "Answer: ************\n",
      "\n",
      "============================================================\n",
      "‚úÖ Agent Workflow Fully Traced!\n",
      "============================================================\n",
      "\n",
      "\n",
      "üîç Agent Trace Hierarchy:\n",
      "\n",
      "agent_execution (CHAIN)\n",
      "‚îú‚îÄ‚îÄ agent_planning (AGENT)\n",
      "‚îÇ   ‚îî‚îÄ‚îÄ OpenAI API call (auto-traced)\n",
      "‚îú‚îÄ‚îÄ get_weather | calculate | generate_random_password (TOOL)\n",
      "‚îî‚îÄ‚îÄ OpenAI API call for final response (auto-traced)\n",
      "\n",
      "Key insights visible:\n",
      "‚úì Which tool was selected by the LLM\n",
      "‚úì Tool execution time\n",
      "‚úì Tool parameters and results\n",
      "‚úì Total agent reasoning time\n",
      "‚úì Token usage across all LLM calls\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-45c5518536beb2b28b26dc504f4397c0&amp;experiment_id=1&amp;trace_id=tr-2b97e15b5f1b5555258214e704875c41&amp;experiment_id=1&amp;trace_id=tr-e143805237b3e0c30d506b9857fe9288&amp;experiment_id=1&amp;version=3.10.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(trace_id=tr-45c5518536beb2b28b26dc504f4397c0), Trace(trace_id=tr-2b97e15b5f1b5555258214e704875c41), Trace(trace_id=tr-e143805237b3e0c30d506b9857fe9288)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the agent\n",
    "print(\"\\nü§ñ Testing agentic workflow with tool tracing...\\n\")\n",
    "\n",
    "query_1 = \"What's the weather in San Francisco?\"\n",
    "answer_1 = run_agent(query_1)\n",
    "\n",
    "print(f\"Query: {query_1}\")\n",
    "print(f\"Answer: {answer_1}\\n\")\n",
    "\n",
    "query_2 = \"Calculate 42 times 2 and divide by 2\"\n",
    "answer_2 = run_agent(query_2)\n",
    "\n",
    "print(f\"Query: {query_2}\")\n",
    "print(f\"Answer: {answer_2}\")\n",
    "\n",
    "query_3 = \"Generate a random password with 12 characters\"\n",
    "answer_3 = run_agent(query_3)\n",
    "\n",
    "print(f\"Query: {query_3}\\n\")\n",
    "print(\"Answer: ************\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Agent Workflow Fully Traced!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "\\nüîç Agent Trace Hierarchy:\n",
    "\n",
    "agent_execution (CHAIN)\n",
    "‚îú‚îÄ‚îÄ agent_planning (AGENT)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ OpenAI API call (auto-traced)\n",
    "‚îú‚îÄ‚îÄ get_weather | calculate | generate_random_password (TOOL)\n",
    "‚îî‚îÄ‚îÄ OpenAI API call for final response (auto-traced)\n",
    "\n",
    "Key insights visible:\n",
    "‚úì Which tool was selected by the LLM\n",
    "‚úì Tool execution time\n",
    "‚úì Tool parameters and results\n",
    "‚úì Total agent reasoning time\n",
    "‚úì Token usage across all LLM calls\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ Agent Tracing Benefits\n",
    "\n",
    "For agentic workflows, tracing reveals:\n",
    "\n",
    "1. **Decision Making**: Which tool was chosen and why?\n",
    "2. **Tool Performance**: How long does each tool take?\n",
    "3. **Error Tracking**: Which tool failed?\n",
    "4. **Cost Analysis**: How many LLM calls per agent run?\n",
    "5. **Optimization**: Can we skip unnecessary steps?\n",
    "\n",
    "**Essential for debugging complex agents!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 9: Advanced Debugging Techniques\n",
    "\n",
    "Let's explore how to use traces for debugging, besides inspection and retrospection.\n",
    "Use the MLflow assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üêõ Testing error tracing...\n",
      "\n",
      "‚úÖ Success case: {'processed': True, 'value': 'test'}\n",
      "\n",
      "Testing failure case...\n",
      "‚ùå Error: Missing required_field\n",
      "\n",
      "üîç Error details captured in trace!\n",
      "\n",
      "\n",
      "üí° Debugging with Traces:\n",
      "\n",
      "1. Filter traces by error status in UI\n",
      "2. View the failed span (marked in red)\n",
      "3. Check custom attributes:\n",
      "   - What were the inputs?\n",
      "   - What validation step failed?\n",
      "   - What was the error type?\n",
      "4. Compare with successful traces\n",
      "5. Reproduce the issue with exact inputs\n",
      "6. Use MLflow Assistant to get insights on the failed traces and root cause\n",
      "\n",
      "Attributes logged BEFORE the error help identify root cause!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=tr-c4a35f33b75404c390de2cdd5592ee79&amp;experiment_id=1&amp;trace_id=tr-4e115ae969e593b16210085760852ea5&amp;experiment_id=1&amp;version=3.10.0\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "[Trace(trace_id=tr-c4a35f33b75404c390de2cdd5592ee79), Trace(trace_id=tr-4e115ae969e593b16210085760852ea5)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Debugging example: Trace a buggy function, which can raise an error\n",
    "\n",
    "@mlflow.trace(name=\"buggy_processor\", span_type=\"PARSER\")\n",
    "def process_with_validation(data: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Fake function with potential errors.\n",
    "    \"\"\"\n",
    "    span = mlflow.get_current_active_span()\n",
    "    span.set_attributes({\n",
    "        \"input_keys\": list(data.keys())\n",
    "    })\n",
    "    \n",
    "    # Log intermediate state for debugging\n",
    "    span.set_attributes({\n",
    "        \"validation_step\": \"checking_required_fields\"\n",
    "    })\n",
    "    \n",
    "    # This might raise an error\n",
    "    if \"required_field\" not in data:\n",
    "        span.set_attributes({\n",
    "            \"error_type\": \"missing_field\"\n",
    "        })\n",
    "        raise ValueError(\"Missing required_field\")\n",
    "    span.set_attributes({\n",
    "        \"validation_step\": \"passed\"\n",
    "    })\n",
    "    \n",
    "    # Process data\n",
    "    result = {\"processed\": True, \"value\": data.get(\"required_field\")}\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"\\nüêõ Testing error tracing...\\n\")\n",
    "\n",
    "# Success case\n",
    "try:\n",
    "    result = process_with_validation({\"required_field\": \"test\"})\n",
    "    print(f\"‚úÖ Success case: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "# Failure case\n",
    "print(\"\\nTesting failure case...\")\n",
    "try:\n",
    "    result = process_with_validation({\"wrong_field\": \"test\"})\n",
    "    print(f\"‚úÖ Success case: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"\\nüîç Error details captured in trace!\")\n",
    "\n",
    "print(\"\"\"\n",
    "\\nüí° Debugging with Traces:\n",
    "\n",
    "1. Filter traces by error status in UI\n",
    "2. View the failed span (marked in red)\n",
    "3. Check custom attributes:\n",
    "   - What were the inputs?\n",
    "   - What validation step failed?\n",
    "   - What was the error type?\n",
    "4. Compare with successful traces\n",
    "5. Reproduce the issue with exact inputs\n",
    "6. Use MLflow Assistant to get insights on the failed traces and root cause\n",
    "\n",
    "Attributes logged BEFORE the error help identify root cause!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 10: Performance Analysis\n",
    "\n",
    "Use traces to identify performance bottlenecks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
      "‚ïë         Performance Analysis with Traces                     ‚ïë\n",
      "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
      "\n",
      "In the MLflow UI, you can:\n",
      "\n",
      "1. üìä TIMELINE VIEW:\n",
      "   - See which operations take the most time\n",
      "   - Identify serial vs parallel operations\n",
      "   - Find bottlenecks visually\n",
      "\n",
      "2. üìà AGGREGATE METRICS:\n",
      "   - Average latency per span type\n",
      "   - P50, P95, P99 latencies\n",
      "   - Success rate per operation\n",
      "\n",
      "3. üîç COMPARISON:\n",
      "   - Compare traces before/after optimization\n",
      "   - A/B test different implementations\n",
      "   - Track performance over time\n",
      "\n",
      "4. üí° OPTIMIZATION STRATEGIES:\n",
      "\n",
      "   If retrieval is slow:\n",
      "   - Check embedding generation time\n",
      "   - Optimize vector search\n",
      "   - Optimize prompt with GEPA\n",
      "\n",
      "   If LLM calls are slow:\n",
      "   - Reduce max_tokens\n",
      "   - Use streaming responses\n",
      "   - Try smaller models to reduce latency or curb costs\n",
      "\n",
      "   If overall latency is high:\n",
      "   - Parallelize independent operations\n",
      "   - Cache frequent queries\n",
      "   - Optimize prompt length\n",
      "\n",
      "5. üìä METRICS TO TRACK:\n",
      "   - End-to-end latency\n",
      "   - Per-operation latency\n",
      "   - Token usage and cost\n",
      "   - Error rate\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Performance analysis example\n",
    "print(\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë         Performance Analysis with Traces                     ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "In the MLflow UI, you can:\n",
    "\n",
    "1. üìä TIMELINE VIEW:\n",
    "   - See which operations take the most time\n",
    "   - Identify serial vs parallel operations\n",
    "   - Find bottlenecks visually\n",
    "\n",
    "2. üìà AGGREGATE METRICS:\n",
    "   - Average latency per span type\n",
    "   - P50, P95, P99 latencies\n",
    "   - Success rate per operation\n",
    "\n",
    "3. üîç COMPARISON:\n",
    "   - Compare traces before/after optimization\n",
    "   - A/B test different implementations\n",
    "   - Track performance over time\n",
    "\n",
    "4. üí° OPTIMIZATION STRATEGIES:\n",
    "   \n",
    "   If retrieval is slow:\n",
    "   - Check embedding generation time\n",
    "   - Optimize vector search\n",
    "   - Optimize prompt with GEPA\n",
    "   \n",
    "   If LLM calls are slow:\n",
    "   - Reduce max_tokens\n",
    "   - Use streaming responses\n",
    "   - Try smaller models to reduce latency or curb costs\n",
    "   \n",
    "   If overall latency is high:\n",
    "   - Parallelize independent operations\n",
    "   - Cache frequent queries\n",
    "   - Optimize prompt length\n",
    "\n",
    "5. üìä METRICS TO TRACK:\n",
    "   - End-to-end latency\n",
    "   - Per-operation latency\n",
    "   - Token usage and cost\n",
    "   - Error rate\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "1. ‚úÖ When to use manual tracing vs. autologging\n",
    "2. ‚úÖ The `@mlflow.trace` decorator for custom functions\n",
    "3. ‚úÖ Span types and naming conventions\n",
    "4. ‚úÖ Adding custom attributes with `span = mlflow.get_current_active_span(); span.set_attributes({...})`\n",
    "5. ‚úÖ Building hierarchical traces (parent-child relationships)\n",
    "6. ‚úÖ Tracing complete RAG pipelines end-to-end\n",
    "7. ‚úÖ Tracing agentic workflows with tool usage\n",
    "8. ‚úÖ Advanced debugging techniques with traces and MLflow Assistant\n",
    "9. ‚úÖ Performance analysis and optimization strategies\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Combine** autologging and manual tracing for complete coverage\n",
    "- **Use span types** for better organization and filtering\n",
    "- **Add custom attributes** for debugging and analysis\n",
    "- **Build hierarchies** to represent complex workflows accurately\n",
    "- **Trace everything** from retrieval to generation to validation\n",
    "- **Use traces** for debugging, performance, and optimization\n",
    "\n",
    "### Production Best Practices\n",
    "\n",
    "1. **Always trace** in development and staging\n",
    "3. **Monitor key metrics** from traces (latency, errors, costs)\n",
    "4. **Set up alerts** for anomalies\n",
    "5. **Review traces** during incident response\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "**üìì Notebook 1.5: Prompt Management and optimization**\n",
    "\n",
    "Learn how to:\n",
    "- Create reusable prompt templates\n",
    "- Version prompts systematically\n",
    "- Link prompts to experiments and traces\n",
    "- Share prompts across your team\n",
    "- Track prompt performance\n",
    "- Optimize prompt with GEPA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
